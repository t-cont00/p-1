import asyncio
import aiohttp
import json
import re
import urllib3

# Suppress InsecureRequestWarning from urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# API Configuration
API_URL = "https://server.server.abc.com/rest/api/1.0/projects/CND/repos"
AUTH_TOKEN = "(Auth-token)"
HEADERS = {
    "Authorization": f"Bearer {AUTH_TOKEN}",
    "Content-Type": "application/json"
}

# Condition Keywords
SEARCH_TERMS = [
    "requiredDuringSchedulingIgnoredDuringExecution",
    "preferredDuringSchedulingIgnoredDuringExecution"
]

# Max concurrent requests
MAX_CONCURRENT_TASKS = 10  

async def fetch(session, url):
    """Fetch API response asynchronously with error handling."""
    try:
        async with session.get(url, headers=HEADERS, ssl=False, timeout=10) as response:
            if response.status == 200:
                return await response.text()
            else:
                print(f"‚ö†Ô∏è API Error {response.status}: {url}")
                return None
    except Exception as e:
        print(f"‚ùå Request Failed: {url} - {e}")
        return None

async def check_yaml_conditions(session, project_name, file_path):
    """Check if a YAML file contains the required conditions."""
    file_url = f"{API_URL}/{project_name}/browse/{file_path}"
    file_content = await fetch(session, file_url)

    if file_content and any(term in file_content for term in SEARCH_TERMS):
        print(f"‚úÖ Condition found in: {file_url}")
        return True

    return False

async def search_yaml_files(session, project_name, base_path):
    """Recursively search for YAML files in the given path."""
    folder_url = f"{API_URL}/{project_name}/browse/{base_path}"
    response = await fetch(session, folder_url)

    if not response:
        return

    try:
        data = json.loads(response)
        items = [item["name"] for item in data.get("values", [])]
    except json.JSONDecodeError:
        print(f"‚ö†Ô∏è JSON Parsing Error: {folder_url}")
        return

    tasks = []
    for item in items:
        full_path = f"{base_path}/{item}"
        if re.search(r"\.ya?ml$", item, re.IGNORECASE):  # Check if it's a YAML file
            tasks.append(check_yaml_conditions(session, project_name, full_path))
        else:
            tasks.append(search_yaml_files(session, project_name, full_path))

    await asyncio.gather(*tasks)

async def process_project(project_name):
    """Process a single project asynchronously."""
    async with aiohttp.ClientSession() as session:
        print(f"üîç Searching in project: {project_name}")
        await search_yaml_files(session, project_name, "k8s/envs/pr")

async def main():
    """Main function to run all projects in parallel with rate limiting."""
    with open("repo.txt") as f:
        projects = [line.strip() for line in f if line.strip()]

    # Limit concurrent tasks
    sem = asyncio.Semaphore(MAX_CONCURRENT_TASKS)

    async def limited_process(project):
        async with sem:
            await process_project(project)

    await asyncio.gather(*(limited_process(proj) for proj in projects))

if __name__ == "__main__":
    asyncio.run(main())
