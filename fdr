import asyncio
import aiohttp
import json
import re
import urllib3
import csv
import os

# CSV output file
CSV_FILE = "ORAPRODLDAP.csv"

# Create CSV with headers if not exists
if not os.path.exists(CSV_FILE):
    with open(CSV_FILE, mode="w", newline="") as file:
        writer = csv.writer(file)
        writer.writerow(["Project Name", "Lifecycle Folder Path"])

# Suppress SSL warnings
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# API Configuration
API_URL = "https://server.server.abe.com/rest/api/1.0/projects/abc/repos"
AUTH_TOKEN = "your_auth_token_here"

HEADERS = {
    "Authorization": f"Bearer {AUTH_TOKEN}",
    "Content-Type": "application/json"
}

# Max concurrent projects
MAX_CONCURRENT_TASKS = 10

async def fetch(session, url):
    """Fetch API response asynchronously with error handling."""
    try:
        async with session.get(url, headers=HEADERS, ssl=False, timeout=10) as response:
            if response.status == 200:
                return await response.json()
            else:
                # print(f"‚ö†Ô∏è API Error {response.status}: {url}")
                return None
    except Exception as e:
        # print(f"‚ùå Request Failed: {url} - {e}")
        return None

async def search_lifecycle_folders(session, project_name, base_path):
    """Recursively search for folders named 'lifecycle'."""
    folder_url = f"{API_URL}/{project_name}/browse/{base_path}"
    response = await fetch(session, folder_url)

    if not response:
        return

    try:
        items = response.get("children", {}).get("values", [])
        if not items:
            return
    except json.JSONDecodeError:
        return

    tasks = []

    for item in items:
        name = item.get("path", {}).get("name")
        item_type = item.get("type")
        full_path = f"{base_path}/{name}"

        if not name or not item_type:
            continue  # Skip invalid entries

        if item_type == "DIRECTORY":
            if name.lower() == "lifecycle":
                print(f"‚úÖ Found 'lifecycle' folder: {project_name} - {full_path}")
                with open(CSV_FILE, mode="a", newline="") as file:
                    writer = csv.writer(file)
                    writer.writerow([project_name, full_path])
            # Recurse deeper into subdirectories
            tasks.append(search_lifecycle_folders(session, project_name, full_path))

    await asyncio.gather(*tasks)

async def process_project(project_name):
    """Process a single project asynchronously."""
    async with aiohttp.ClientSession() as session:
        print(f"\nüîç Searching in project: {project_name}")
        await search_lifecycle_folders(session, project_name, "k8s/envs/pr")

async def main():
    """Main function to run all projects in parallel."""
    if not os.path.exists("repo.txt"):
        print("‚ùå repo.txt not found!")
        return

    with open("repo.txt") as f:
        projects = [line.strip() for line in f if line.strip()]

    if not projects:
        print("‚ùå No projects found in repo.txt")
        return

    sem = asyncio.Semaphore(MAX_CONCURRENT_TASKS)

    async def limited_process(project):
        async with sem:
            await process_project(project)

    await asyncio.gather(*(limited_process(proj) for proj in projects))

if __name__ == "__main__":
    asyncio.run(main())




-------------------------------

import asyncio
import aiohttp
import json
import re
import urllib3
import csv
import os

# CSV output file
CSV_FILE = "ORAPRODLDAP.csv"

# Create CSV with headers if not exists
if not os.path.exists(CSV_FILE):
    with open(CSV_FILE, mode="w", newline="") as file:
        writer = csv.writer(file)
        writer.writerow(["Project Name", "Lifecycle Folder Path"])

# Suppress SSL warnings
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# API Configuration
API_URL = "https://server.server.abe.com/rest/api/1.0/projects/abc/repos"
AUTH_TOKEN = "your_auth_token_here"

HEADERS = {
    "Authorization": f"Bearer {AUTH_TOKEN}",
    "Content-Type": "application/json"
}

# Max concurrent projects
MAX_CONCURRENT_TASKS = 10

async def fetch(session, url):
    """Fetch API response asynchronously with error handling."""
    try:
        async with session.get(url, headers=HEADERS, ssl=False, timeout=10) as response:
            if response.status == 200:
                return await response.json()
            else:
                return None
    except Exception as e:
        return None

async def search_lifecycle_folders(session, project_name, base_path):
    """Recursively search for folders named 'lifecycle' or under 'lifecycle'."""
    folder_url = f"{API_URL}/{project_name}/browse/{base_path}"
    response = await fetch(session, folder_url)

    if not response:
        return

    try:
        items = response.get("children", {}).get("values", [])
        if not items:
            return
    except json.JSONDecodeError:
        return

    tasks = []

    for item in items:
        path_info = item.get("path", {})
        item_type = item.get("type")

        # Safely extract using 'toString' if available
        full_path = path_info.get("toString")  # This is the correct full path
        name = path_info.get("name")  # current folder/file name
        parent = path_info.get("parent")  # parent folder name

        if not full_path or not name or not item_type:
            continue  # Skip invalid entries

        if item_type == "DIRECTORY":
            if name.lower() == "lifecycle" or parent.lower() == "lifecycle":
                print(f"‚úÖ Found lifecycle folder: {project_name} - {full_path}")
                with open(CSV_FILE, mode="a", newline="") as file:
                    writer = csv.writer(file)
                    writer.writerow([project_name, full_path])

            # Continue searching inside the directory
            tasks.append(search_lifecycle_folders(session, project_name, full_path))

    await asyncio.gather(*tasks)

async def process_project(project_name):
    """Process a single project asynchronously."""
    async with aiohttp.ClientSession() as session:
        print(f"\nüîç Searching in project: {project_name}")
        await search_lifecycle_folders(session, project_name, "k8s/envs/pr")

async def main():
    """Main function to run all projects in parallel."""
    if not os.path.exists("repo.txt"):
        print("‚ùå repo.txt not found!")
        return

    with open("repo.txt") as f:
        projects = [line.strip() for line in f if line.strip()]

    if not projects:
        print("‚ùå No projects found in repo.txt")
        return

    sem = asyncio.Semaphore(MAX_CONCURRENT_TASKS)

    async def limited_process(project):
        async with sem:
            await process_project(project)

    await asyncio.gather(*(limited_process(proj) for proj in projects))

if __name__ == "__main__":
    asyncio.run(main())

