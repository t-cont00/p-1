import asyncio
import aiohttp
import json
import re
import urllib3

# Suppress SSL warnings
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# API Configuration
API_URL = "https://server.server.abc.com/rest/api/1.0/projects/CND/repos"
AUTH_TOKEN = "(Auth-token)"
HEADERS = {
    "Authorization": f"Bearer {AUTH_TOKEN}",
    "Content-Type": "application/json"
}

# Condition Keywords
SEARCH_TERMS = [
    "requiredDuringSchedulingIgnoredDuringExecution",
    "preferredDuringSchedulingIgnoredDuringExecution"
]

# Max concurrent tasks
MAX_CONCURRENT_TASKS = 10

async def fetch(session, url):
    """Fetch API response asynchronously with error handling."""
    try:
        async with session.get(url, headers=HEADERS, ssl=False, timeout=10) as response:
            if response.status == 200:
                return await response.json()
            else:
                print(f"‚ö†Ô∏è API Error {response.status}: {url}")
                return None
    except Exception as e:
        print(f"‚ùå Request Failed: {url} - {e}")
        return None

async def check_yaml_conditions(session, project_name, file_path):
    """Check if a YAML file contains the required conditions."""
    file_url = f"{API_URL}/{project_name}/browse/{file_path}"
    print(f"üîç Checking YAML file: {file_url}")

    file_content = await fetch(session, file_url)

    if file_content:
        file_text = json.dumps(file_content)  # Convert to string
        for term in SEARCH_TERMS:
            if term in file_text:
                print(f"‚úÖ Condition found in {project_name}: {file_url}")
                return (project_name, file_url)

    return None

async def collect_yaml_files(session, project_name, base_path, yaml_files):
    """Recursively search for YAML files and store paths."""
    folder_url = f"{API_URL}/{project_name}/browse/{base_path}"
    print(f"üìÇ Fetching directory: {folder_url}")

    response = await fetch(session, folder_url)
    if not response:
        return

    items = response.get("children", {}).get("values", [])

    for item in items:
        name = item.get("path", {}).get("name")
        item_type = item.get("type")
        full_path = f"{base_path}/{name}"

        if not name or not item_type:
            continue  # Skip invalid entries

        if item_type == "FILE" and re.search(r"\.ya?ml$", name, re.IGNORECASE):
            print(f"üìù Found YAML: {full_path}")
            yaml_files.append((project_name, full_path))  # Store YAML file path
        elif item_type == "DIRECTORY":
            print(f"üìÅ Found folder: {full_path}, diving in...")
            await collect_yaml_files(session, project_name, full_path, yaml_files)

async def process_project(project_name):
    """Process a single project: Find YAML files first, then scan them."""
    yaml_files = []  # List to store YAML file paths

    async with aiohttp.ClientSession() as session:
        print(f"\nüîé Searching in project: {project_name}")
        await collect_yaml_files(session, project_name, "k8s/envs/pr", yaml_files)  # Collect YAML files

        if not yaml_files:
            print(f"üö´ No YAML files found in {project_name}")
            return

        # Now process found YAML files **in parallel** for condition checking
        sem = asyncio.Semaphore(MAX_CONCURRENT_TASKS)

        async def limited_check_yaml(project, file):
            async with sem:
                return await check_yaml_conditions(session, project, file)

        results = await asyncio.gather(*(limited_check_yaml(prj, f) for prj, f in yaml_files))

        # Filter and display only the files where conditions were found
        results = [res for res in results if res]
        if results:
            print("\n‚úÖ **Matched YAML Files:**")
            for project, file_url in results:
                print(f"üîπ {project}: {file_url}")

async def main():
    """Main function to process all projects with controlled concurrency."""
    with open("repo.txt") as f:
        projects = [line.strip() for line in f if line.strip()]

    if not projects:
        print("‚ö†Ô∏è No projects found in repo.txt")
        return

    # Limit concurrent tasks
    sem = asyncio.Semaphore(MAX_CONCURRENT_TASKS)

    async def limited_process(project):
        async with sem:
            await process_project(project)

    await asyncio.gather(*(limited_process(proj) for proj in projects))

if __name__ == "__main__":
    asyncio.run(main())


-----------------------
import asyncio
import aiohttp
import json
import re
import urllib3
import csv
import os
import yaml

# Constants
CSV_FILE = "ORAPRODLDAP.csv"
REPO_FILE = "repo.txt"
API_URL = "https://server.cserver.ace.com/rest/api/1.0/projects/Cabc/repos"
AUTH_TOKEN = "gfgf"
HEADERS = {
    "Authorization": f"Bearer {AUTH_TOKEN}",
    "Content-Type": "application/json"
}
SEARCH_TERMS = ["ORAPRODLDAP"]  # Modify if more terms are needed
MAX_CONCURRENT_TASKS = 10

# Disable SSL warnings
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# Ensure CSV exists
if not os.path.exists(CSV_FILE):
    with open(CSV_FILE, mode="w", newline="") as file:
        writer = csv.writer(file)
        writer.writerow(["Project Name", "App ID", "File URL"])


async def fetch(session, url):
    """Fetch API response asynchronously with error handling."""
    try:
        async with session.get(url, headers=HEADERS, ssl=False, timeout=10) as response:
            if response.status == 200:
                return await response.json()
            else:
                print(f"‚ö†Ô∏è API Error {response.status}: {url}")
                return None
    except Exception as e:
        print(f"‚ùå Request Failed: {url} - {e}")
        return None


async def check_yaml_conditions(session, project_name, file_path):
    """Check if a YAML file contains the required search term."""
    file_url = f"{API_URL}/{project_name}/browse/{file_path}"
    print(f"üîç Checking YAML file: {file_url}")

    file_content = await fetch(session, file_url)
    if not file_content:
        return False

    # Convert JSON response to plain text
    file_text = json.dumps(file_content)

    # Use regex to match the search term as a whole word
    search_term = SEARCH_TERMS[0]
    pattern = rf"\b{re.escape(search_term)}\b"

    if re.search(pattern, file_text, re.IGNORECASE):
        print(f"‚úÖ Condition found in: {file_url}")

        # Extract app_id using regex
        app_id_match = re.findall(r"app-(\d+)-.*", file_text)
        app_id = app_id_match[0] if app_id_match else "N/A"

        # Write results to CSV
        with open(CSV_FILE, mode="a", newline="") as file:
            writer = csv.writer(file)
            writer.writerow([project_name, app_id, file_url])

        return True
    return False


async def search_yaml_files(session, project_name, base_path):
    """Recursively search for YAML files in the given path."""
    folder_url = f"{API_URL}/{project_name}/browse/{base_path}"
    print(f"üìÇ Fetching directory: {folder_url}")

    response = await fetch(session, folder_url)
    if not response:
        return

    try:
        # Extract items from JSON response
        items = response.get("children", {}).get("values", [])
        if not items:
            print(f"‚ö†Ô∏è No files or directories found in {folder_url}")
            return
    except json.JSONDecodeError:
        print(f"‚ùå JSON Parsing Error at {folder_url}")
        return

    tasks = []
    for item in items:
        name = item.get("path", {}).get("name")
        item_type = item.get("type")
        full_path = f"{base_path}/{name}"

        if not name or not item_type:
            continue

        if item_type == "FILE" and re.search(r"\.ya?ml$", name, re.IGNORECASE):
            print(f"üìÑ Found YAML: {full_path}")
            tasks.append(check_yaml_conditions(session, project_name, full_path))
        elif item_type == "DIRECTORY":
            print(f"üìÅ Found folder: {full_path}, searching inside...")
            tasks.append(search_yaml_files(session, project_name, full_path))

    await asyncio.gather(*tasks)


async def process_project(project_name):
    """Process a single project asynchronously."""
    async with aiohttp.ClientSession() as session:
        print(f"\nüîé Searching in project: {project_name}")
        await search_yaml_files(session, project_name, "k8s/envs/pr")


async def main():
    """Main function to run all projects in parallel with rate limiting."""
    if not os.path.exists(REPO_FILE):
        print(f"‚ö†Ô∏è File {REPO_FILE} not found.")
        return

    with open(REPO_FILE) as f:
        projects = [line.strip() for line in f if line.strip()]

    if not projects:
        print("‚ö†Ô∏è No projects found in repo.txt")
        return

    sem = asyncio.Semaphore(MAX_CONCURRENT_TASKS)

    async def limited_process(project):
        async with sem:
            await process_project(project)

    await asyncio.gather(*(limited_process(proj) for proj in projects))


if __name__ == "__main__":
    asyncio.run(main())
